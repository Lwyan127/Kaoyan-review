# 扩散模型（Diffusion Model）

**扩散模型**是一种生成模型，核心思想是通过**两步过程**学习数据分布：

1. **正向扩散**：将真实数据（如图像）逐步添加噪声，最终变成纯噪声（类似把照片一步步模糊）。
2. **反向去噪**：训练神经网络从纯噪声开始，每一步去除部分噪声，逐步恢复真实数据（类似从模糊照片还原原图）。

**训练时**，网络学习预测每一步的噪声，通过最小化预测噪声与实际噪声的差距来优化。相比 GAN，扩散模型**训练更稳定**（无模式崩溃），生成样本**多样性更强**，且适合高分辨率任务（如 Stable Diffusion 生成高清图像）。尽管生成**需多步迭代（速度较慢）**，但其鲁棒性和灵活性使其在图像、文本、3D 生成等领域广泛应用。

| **特性**     | **扩散模型**         | **GANs**                     |
| ------------ | -------------------- | ---------------------------- |
| **训练目标** | 回归问题（预测噪声） | 对抗博弈（生成器 vs 判别器） |
| **稳定性**   | 更稳定，无模式崩溃   | 易模式崩溃，训练困难         |
| **多样性**   | 高（通过随机采样）   | 依赖架构设计，可能受限       |
| **采样速度** | 较慢（需多步迭代）   | 快速（单次前向传播）         |

# GANs

一种无监督学习框架，通过两个神经网络（生成器和判别器）的博弈优化，学习真实数据的分布。

#### 结构与原理

- **生成器（Generator）：**
  - 输入：随机噪声（如高斯分布）。
  - 目标：生成假样本（如伪造图像），欺骗判别器。
- **判别器（Discriminator）：**
  - 输入：真实样本或生成样本。
  - 目标：区分输入是真实数据还是生成数据。
- **对抗训练：**
  - 生成器优化目标：**最大化判别器误判的概率。**
  - 判别器优化目标：**最大化正确分类的概率。**
  - 最终目标：两者交替优化，达到纳什均衡，生成器生成的样本与真实数据分布一致。

#### 优点

- 生成速度快（单次前向传播），适合实时应用。
- 无需显式概率建模，直接学习数据分布。

#### 缺点

- 训练不稳定，会导致梯度消失，导致模型无法有效更新参数。
- GANs 易模式崩溃（生成器在训练中陷入局部最优，仅生成少数几种相似样本），尤其在隐私训练中（如 DP-GANs）。

# 差分隐私（Differential Privacy）

## **核心概念**

**差分隐私**是一种严格的数学框架，用于保护数据隐私，确保单个数据点的加入或删除不会显著影响模型输出。 

**核心思想**：通过向数据或模型添加**可控噪声**，使攻击者无法通过模型输出推断出任何个体的信息。

## **关键技术**

1. **梯度裁剪（Gradient Clipping）**
   - 限制每个样本对梯度的贡献，防止单个数据点主导模型训练。
   - **公式**：$ \text{clip}_C(g) = \min\left(1, \frac{C}{\|g\|_2}\right) g $  , C 为裁剪阈值，确保梯度范数不超过 C。
2. **噪声注入（Noise Addition）**
   - 向梯度或查询结果中添加高斯噪声，掩盖真实数据的影响。
   - **公式**： $ \tilde{g} = \frac{1}{B} \sum_{i=1}^B \text{clip}_C(g_i) + \mathcal{N}(0, \sigma^2 I) $  , B 为批量大小，$\sigma$ 控制噪声强度。
3. **隐私预算（Privacy Budget）**
   - **ε（epsilon）**：隐私强度，ε 越小隐私保护越强。
   - **δ（delta）**：允许的失败概率，δ 越小隐私越严格。
   - **公式**： $ \text{Pr}[M(D) \in S] \leq e^\epsilon \cdot \text{Pr}[M(D') \in S] + \delta $ ,D 和 \(D'\) 为相邻数据集，M 为隐私机制。

## **核心优势**

- **严格数学保证**：通过 ε 和 δ 量化隐私风险，避免 “黑箱” 假设。
- **通用框架**：适用于任何统计模型（如神经网络、回归模型）。
- **抗攻击能力**：抵御成员推理攻击、重构攻击等隐私泄露风险。

## **局限性**

- **隐私 - 效用权衡**：更强的隐私（更小 ε）会导致模型性能下降。
- **计算成本**：噪声注入可能增加训练时间或降低收敛速度。
- **参数调优**：需平衡 ε、δ、裁剪阈值和噪声强度，调参复杂。

# 梯度裁剪和添加噪声通常是配合使用的原因

- **梯度裁剪**：用于限制每个数据点对梯度更新的影响，防止某些数据点的梯度过大，对整体梯度产生过大影响，从而增加隐私风险。简单来说，就是控制单个数据点对最终模型训练结果的影响力，避免其过度 “主导” 训练过程而导致隐私泄露风险上升 。
- **添加噪声**：在梯度裁剪的基础上，对裁剪后的梯度添加噪声（通常是拉普拉斯噪声或高斯噪声），进一步掩盖单个数据点对输出的具体贡献，使得模型在统计上无法区分单个数据点的存在与否，从而实现隐私保护。

## 只使用梯度裁剪的局限性

仅进行梯度裁剪，虽然能限制单个数据点的影响力，但并**没有从根本上掩盖数据特征信息。攻击者仍有可能通过分析梯度数据，推测出特定个体的数据信息**，无法严格满足差分隐私的要求。例如在联邦学习中，若客户端只对梯度进行裁剪而不添加噪声，攻击者可以通过分析上传的梯度，尝试还原用户的私有训练数据，存在隐私泄露风险。

## 只使用添加噪声的局限性

如果只添加噪声而不进行梯度裁剪，**当存在个别数据点产生的梯度过大时，添加的噪声可能无法有效掩盖该数据点的影响**。因为噪声的强度需要与数据的敏感度和分布相适配，对于极端的梯度值，若不加以限制，可能需要非常大的噪声才能实现隐私保护，但过大的噪声又会严重影响模型的准确性和实用性，导致模型性能大幅下降。

# 训练噪声

这里的 “训练噪声” 主要指训练过程中因目标函数估计不精确产生的不确定性，具体包含两方面：

- **非私有 DM 的固有噪声**：非私有扩散模型（DM）在近似目标函数期望时，仅用单个蒙特卡洛样本（每个数据点对应单一噪声样本），导致**损失计算存在随机性**。例如，每次迭代中损失值波动大，训练过程不稳定。
- **DP-SGD 引入的额外噪声**：在 DP-SGD 训练中，**梯度裁剪和噪声注入会进一步增加训练过程的方差**。例如，梯度裁剪限制单样本影响，噪声注入掩盖真实梯度，两者叠加使目标函数的优化方向更难精准捕捉，加剧训练噪声。

# DP-SGD 训练 DPDMs 的挑战

1. **优化难题**：DP-SGD 中梯度裁剪与噪声添加影响优化效率。盲目减少噪声会压缩隐私预算允许的训练迭代次数；且噪声范数与模型参数数量线性相关，传统非私有扩散模型（DM）的设置（小批量、多迭代、高度过参数化）不再适用。
2. **隐私成本限制**：每次训练迭代消耗隐私预算，无法像非私有 DM 那样依赖大量迭代抵消训练噪声。

# 噪声多样性（Noise Multiplicity）解决方案

1. **非私有 DM 的局限性**：非私有 DM 通过单蒙特卡洛样本近似目标函数中的期望，**训练损失噪声大，依赖 “大量迭代 + 指数移动平均（EMA）” 优化。**但 DP 场景下，迭代次数受限，且梯度裁剪、噪声注入会引入额外方差，需更稳定的目标函数。
2. **噪声多样性的实现**：对每个数据点，通过多个噪声样本的平均值估计目标函数中的期望，替换非私有 DM 的单样本近似。例如，修改目标函数计算方式，用噪声样本平均降低噪声，且不增加额外隐私成本。
3. **优势**：在差分隐私框架下，以简单方式优化训练目标，平衡隐私保护与训练效率，适配 DP-SGD 的约束。

# 非私有扩散模型不采用噪声多样性减少迭代

- **迭代成本无约束**：非私有场景无需考虑隐私预算消耗，可通过大量迭代训练抵消目标函数的噪声问题。**搭配指数移动平均（EMA）等技术，能有效优化模型，无需额外改进目标函数结构。**传统非私有扩散模型中，单蒙特卡洛样本近似目标函数的方式虽有噪声，但通过 “大量迭代 + EMA” 已能实现稳定训练，最终效果达标，缺乏改进动力。
- **计算资源权衡**：**噪声多样性需对多个噪声样本计算并平均，增加计算开销。**非私有模型更倾向简单直接的训练方案，单样本近似实现成本低，无需为减少迭代而引入额外计算负担。

# 配置

## 神经网络

使用较小的神经网络，我们使用的参数数量 1.75M。

小模型因参数少，噪声对梯度的干扰更小，训练更稳定。

## 选取样本

在扩散模型中，噪声水平数值越大，噪声干扰越强（如图像被严重噪声破坏的状态）。**对较大噪声要赋予足够权重的分布**，指在采样噪声水平时，让高噪声状态的图片有更高的被选中概率。以 v-prediction 分布为例：

- **学习全局结构**：当噪声水平较大时，模型专注学习数据的全局、粗略结构（如图像轮廓等低频信息），这是生成视觉连贯样本的关键。
- **应对隐私训练挑战**：在差分隐私训练（如 DP-SGD）中，梯度裁剪和噪声注入会干扰高噪声水平的训练。对大 噪声水平赋予权重，**能让模型在隐私约束下，仍优先捕捉数据核心全局特征**，提升生成质量，尤其适用于高隐私设置（小 ε ）场景。

## DP-SGD设置

在 DP-SGD 中，**较大的批量大小作用**显著，即每次训练迭代中选取用于计算梯度、更新模型参数的样本数量。例如，在 MNIST/Fashion-MNIST 上使用批量大小 4096，意味着每次训练迭代会同时处理 4096 个样本。

- **优化隐私 - 效用平衡**：大批量可降低单个样本对梯度的影响，结合差分隐私的噪声添加，既能保护隐私，又能减少噪声对模型优化的干扰，提升训练效果。
- **提升梯度稳定性**：批量样本的梯度经平均后更接近真实梯度方向，使训练过程更稳定，尤其在添加噪声后，大批量能有效缓解噪声对梯度估计的破坏。

### **同时还要使用较小的裁剪参数**

## 使用Opacus库来实现DP-SGD

# Distill-SD：轻量级稳定扩散模型

# FID

FID 是一种用于评估生成图像质量的**统计距离指标**，通过比较生成图像与真实图像的统计分布差异来衡量模型性能。其核心思想是：**分布越接近，生成图像越真实**。

1. 对于生成图像集和真实图像集，分别通过**Inception网络**计算它们的特征表示。这一步骤会得到每个图像集的特征向量。

2. 计算每个集合的特征向量的均值和协方差矩阵。具体参数有：**生成图像的特征向量的均值和协方差矩阵 ，真实图像的特征向量的均值和协方差矩阵**

3. 具体计算公式为：

   $FID = ||\mu_1 - \mu_2||^2 + Tr(\Sigma_1 + \Sigma_2 - 2\sqrt{\Sigma_1\Sigma_2})$

# 扩散模型详细

#### **1. 核心思想**

扩散模型通过**正向扩散过程**和**反向去噪过程**学习数据分布。其核心是逐步将真实数据转化为噪声（正向），并通过神经网络学习如何从噪声中恢复真实数据（反向）。

#### **2. 正向扩散过程（Forward Diffusion Process）**

- **目标**：将真实数据 $x_0 \sim p_{\text{data}}$ 逐步添加噪声，最终变为纯噪声 $x_T \sim \mathcal{N}(0, I)$。
- **公式：**
  - **单步扩散**：在时间步 t，添加高斯噪声： $x_t = \sqrt{\alpha_t}  x_{t-1} + \sqrt{1 - \alpha_t}  \epsilon_{t-1}$, $\quad \epsilon_{t-1} \sim \mathcal{N}(0, I)$ 其中 $\alpha_t = 1 - \beta_t$，$\beta_t$ 是噪声方差调度参数。
  - **累积噪声**：通过重参数化，直接计算 $x_t$ 为初始数据 $x_0$ 和噪声的线性组合： $x_t = \sqrt{\bar{\alpha}_t}  x_0 + \sqrt{1 - \bar{\alpha}_t}  \epsilon, \quad \epsilon \sim \mathcal{N}(0, I)$ 其中 $\bar{\alpha}_t = \prod_{s=1}^t \alpha_s$。

#### **3. 反向去噪过程（Reverse Denoising Process）**

- **目标**：学习从纯噪声 $x_T$逐步恢复真实数据 $x_0$。

- **公式：**
  
  - **单步去噪**：在时间步 t，使用神经网络 $\epsilon_\theta(x_t, t)$ 预测噪声 $\epsilon$，并更新样本： 
  
    $x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) + \sqrt{\frac{1 - \alpha_t}{\alpha_t}}  \epsilon'$  ，其中 $\epsilon' \sim \mathcal{N}(0, I)$ 是随机噪声（用于保持多样性）。
  
  - **无噪声版本**：若仅需确定性去噪，可省略 $\epsilon'$：  $ x_{t-1} = \frac{1}{\sqrt{\alpha_t}} \left( x_t - \frac{1 - \alpha_t}{\sqrt{1 - \bar{\alpha}_t}} \epsilon_\theta(x_t, t) \right) $ 

#### **4. 训练目标（Loss Function）**

- **目标**：训练神经网络 $\epsilon_\theta$ 预测噪声 $\epsilon$，使 $x_{t-1}$ 尽可能接近真实数据。

- **损失函数：**
  - **DDPM 损失**：最小化预测噪声与真实噪声的 L2 距离：
  
    $ \mathcal{L}_{\text{DDPM}} = \mathbb{E}_{x_0, \epsilon, t} \left[ \left\| \epsilon_\theta \left( \sqrt{\bar{\alpha}_t} \, x_0 + \sqrt{1 - \bar{\alpha}_t} \, \epsilon, t \right) - \epsilon \right\|^2 \right] $
  
  - **加权损失**：对不同时间步的损失加权，例如高噪声阶段（早期时间步）赋予更高权重： 
  
    $ \mathcal{L}_{\text{weighted}} = \mathbb{E}_{x_0, \epsilon, t} \left[ \lambda_t \left\| \epsilon_\theta(x_t, t) - \epsilon \right\|^2 \right] $ ， 其中  $ \lambda_t = \frac{1}{\sqrt{1 - \bar{\alpha}_t}} $ 。

#### **5. 采样过程（Sampling）**

- **目标**：从纯噪声 $x_T$ 逐步生成真实数据 $x_0$。
- **算法示例（DDIM 采样）：**
  1. 初始化 $x_T \sim \mathcal{N}(0, I)$。
  2. 对每个时间步 $t = T, T-1, \dots, 1$ ：
     - 预测噪声 $\epsilon_\theta(x_t, t)$。
     - 计算 $x_{t-1}$： $x_{t-1} = \sqrt{\alpha_t} \, x_t + \sqrt{1 - \alpha_t} \, \epsilon' + \sqrt{\frac{1 - \alpha_t}{\alpha_t}} \left( \epsilon_\theta(x_t, t) - \epsilon' \right)$
     - 其中 $\epsilon'$ 是随机噪声（若为确定性采样，则 $\epsilon' = \epsilon_\theta(x_t, t)$）。

#### **6. 理论基础**

- **随机微分方程（SDE）：**
  - **正向 SDE**： $dx_t = -\frac{1}{2} \beta_t x_t \, dt + \sqrt{\beta_t} \, dW_t$ 其中 $dW_t$ 是维纳过程。
  - **反向 SDE**： $dx_t = \left( \frac{1}{2} \beta_t x_t + \sigma_t^2 \nabla \log p(x_t) \right) dt + \sqrt{\beta_t} \, dW_t$ 通过神经网络近似得分函数 $\nabla \log p(x_t)$。
- **概率流 ODE：**
  - 去除反向 SDE 中的随机性，得到确定性 ODE： $dx_t = \left( \frac{1}{2} \beta_t x_t + \sigma_t^2 \nabla \log p(x_t) \right) dt$

#### **7. 关键组件**

- **噪声调度（Noise Schedule）：**
  - 定义 $\beta_t$ 的变化方式，如线性、余弦或指数调度。
  - 示例： $\beta_t = \text{linear}(0.0001, 0.02), \quad \beta_t = \text{cosine}(0.0085, 0.99)$
- **神经网络架构：**
  - 通常使用 U-Net 结构，处理多尺度信息（如 DDPM、DALL-E 2）。
  - 输入包括带噪样本 $x_t$ 和时间步 t 的嵌入。

#### **8. 与 GANs 的对比**

| **特性**     | **扩散模型**         | **GANs**                     |
| ------------ | -------------------- | ---------------------------- |
| **训练目标** | 回归问题（预测噪声） | 对抗博弈（生成器 vs 判别器） |
| **稳定性**   | 更稳定，无模式崩溃   | 易模式崩溃，训练困难         |
| **多样性**   | 高（通过随机采样）   | 依赖架构设计，可能受限       |
| **采样速度** | 较慢（需多步迭代）   | 快速（单次前向传播）         |