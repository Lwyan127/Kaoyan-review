# 机器学习流程

数据获取

数据预处理

# 数据预处理

## 不平衡标签处理

分类问题各类样本数量差大，则数据集不平衡，会导致最终模型偏向多数的那类。

使用**过采样处理**。

注意：

- **要在划分训练集和测试集之后**，在训练集中进行过采样，不然不就相当于改了考试题目。
- **要在标准化、特征选择之后过采样**，不然过采样产生的样本会影响均值等统计值，标准化会有问题。

### 1 随机过采样（ROS）

（Random Over Sampling）

随机复制样本来增多样本

优点：简单好用

缺点：可能导致过拟合

建议数据比较多的时候使用ROS或者一些混合方法

### 2 合成少数类过采样技术（SMOTE）

（Synthetic Minority Over - sampling Technique）

合成少数类样本。方法：在该样本k个最邻近的邻居中	选择一个邻居样本，然后新样本为该样本与邻居样本连线上的随机一点。

优点：减少了过拟合的风险

缺点：计算复杂度比较高。如果k值选的不好，会引入噪声样本。

建议数据集比较小的时候选择SMOTE

## 缺失值处理

### 1 直接删除

用于随机缺失，用数据可视化的办法判断随机缺失。

### 2 填补法

- 均值：分布均匀，无明显异常值
- 中位数：偏态分布，有异常值干扰
- 众数：特征是类别

优点：计算简单

缺点：可能引入偏差

- 用模型预测填补（随机森林补全法，计算复杂，可能模型本身就有误差）

## 数据清洗

连续数据：画箱线图

离散数据：画直方图

但是大多数时候不会清洗异常值，因为不了解特征，异常值也能为模型带来泛化性。

## 离散特征编码

两类：

1. 定序特征（ordinal）：有明显顺序，小学-中学-大学
2. 名义特征（nominal）：只是类别不同

使用**onehot编码**能防止模型将名义变量视为定序变量。

## 问题

### 特征工程和数据预处理的差别在于？

数据预处理：不改变特征的数量，只会修改特征的分布。最多过采样增加样本数量。

特征工程：会增加新特征或者筛去不重要的特征。

### 描述性统计和解释性统计

描述性统计是在建模前看看数据的分布。

解释性统计是在建模后针对模型看看哪个特征最有用处，这个往往是描述性统计第一时间看不出来的。

