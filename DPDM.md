**Diffusion Models（DDPM）：**

扩散模型（Diffusion Models，DMs）是一种用于生成模型的深度学习架构，其主要思想是通过对噪声进行逐步扩散来生成数据。在扩散模型中，数据点逐渐从一个简单的噪声分布（通常是高斯分布）中采样，并经过多次迭代的噪声操作，最终生成模型学习到的数据分布。

https://zhuanlan.zhihu.com/p/685515670

https://zhuanlan.zhihu.com/p/636776166

https://blog.csdn.net/dhaiuda/article/details/135954989

随机微分方程（SDE）与常微分方程（ODE）：https://zhuanlan.zhihu.com/p/667317813

FID（**Fréchet Inception Distance**）：https://blog.csdn.net/qq_24951479/article/details/133914575

关于高斯噪声：https://blog.csdn.net/qq_42722197/article/details/136594938

高偏差和高方差：https://blog.csdn.net/youhuakongzhi/article/details/85258772

用于训练扩散模型的分数函数的目标函数：https://zhuanlan.zhihu.com/p/492587047

公式中 $||...||_2$ 即L2范式：https://blog.csdn.net/weixin_58045467/article/details/131091687

指数移动平均（exponential moving average） https://www.bilibili.com/read/cv24126841/ 

**合成数据：**

在机器学习中，合成数据是通过模型生成的人工数据，而不是从现有数据集中直接采集得到的真实数据。合成数据的目的是模拟现实世界中可能的情况或场景，以便用于训练、测试或验证机器学习模型的性能。

合成数据通常是通过在已有数据的基础上进行变换、扩展或生成来创建的。生成合成数据的方法包括使用生成对抗网络（GANs）、变分自动编码器（VAEs）、扩散模型（Diffusion Models）等生成模型。这些模型可以学习现有数据的分布，并生成与之类似但不完全相同的新数据。

合成数据在机器学习中具有多种应用，例如：

1. 数据增强：通过生成合成数据来增加训练	数据的数量和多样性，以改善模型的泛化能力和鲁棒性。
2. 数据平衡：通过生成合成数据来平衡不同类别之间的数据分布，解决数据不平衡问题。
3. 隐私保护：通过生成合成数据来替代真实数据，在不暴露个人隐私信息的情况下进行模型训练和共享。
4. 生成模型评估：通过生成合成数据来评估生成模型的性能和生成质量，例如使用Fréchet Inception Distance（FID）等指标。

总的来说，合成数据在机器学习中是一种非常有用的工具，可以用于各种场景下的数据增强、模型评估和隐私保护等任务。

**扩散模型参数化：**

扩散模型的参数化是指定义生成模型的网络结构和参数。一般来说，扩散模型由两个主要组件组成：噪声生成网络和噪声处理网络。

1. 噪声生成网络：这个网络接收一个简单的噪声样本（通常是从高斯分布中采样得到的）作为输入，并生成一个随机噪声序列。这个噪声序列会逐步扩散，最终用于生成数据点。
2. 噪声处理网络：这个网络接收噪声序列作为输入，并逐步处理噪声，以生成最终的数据点。噪声处理网络的结构可以是卷积神经网络（CNN）、自注意力网络（Self-Attention）等。

**扩散模型采样算法：**

扩散模型的采样算法是指生成模型如何从噪声分布中采样并生成数据点的过程。在扩散模型中，通常使用随机梯度 Langevin 动力学（Stochastic Gradient Langevin Dynamics，SGLD）算法来进行采样。该算法通过在噪声序列上施加噪声，并根据模型的损失函数梯度进行迭代更新，逐步生成模型学习到的数据分布。在每一步迭代中，都会生成一个数据点，然后利用该数据点进行模型参数的更新和优化。

总的来说，扩散模型的参数化和采样算法共同构成了模型的核心结构，决定了模型如何从简单的噪声分布中逐步生成复杂的数据分布。这种方法不仅在生成逼真的图像数据方面表现出色，还能够提供对生成过程的可解释性和控制性。



# Differentially Private Diffusion Models

https://www.bilibili.com/video/BV1Gu4y1Z74u

## abstract

虽然现代机器学习模型依赖于越来越大的训练数据集，但在涉及隐私敏感领域时，数据往往受到限制。利用差分隐私（DP）在敏感数据上训练的生成模型可以规避这一挑战，提供对合成数据的访问。我们建立在最近扩散模型（DMs）取得的成功基础上，引入差分隐私扩散模型（DPDMs），利用差分隐私随机梯度下降（DP-SGD）来实现隐私保护。我们研究了扩散模型参数化和采样算法，在DPDMs中它们被证明是关键因素，并提出了噪声多样性，这是针对扩散模型训练而量身定制的DP-SGD的强大改进。我们在图像生成基准测试上验证了我们的新型DPDM，在所有实验中均取得了最先进的性能。此外，在标准基准测试中，基于DPDM生成的合成数据训练的分类器与特定任务的DP-SGD训练的分类器表现相当，这在以前的DP生成模型中尚未得到证明。项目页面和代码：https://nv-tlabs.github.io/DPDM。

## 1 introduction

现代深度学习通常需要大量的训练数据。然而，在涉及隐私敏感领域获取大型数据集通常很困难。为了规避这一挑战，训练在敏感数据上的生成模型可以提供对大量合成数据的访问，这些数据可以灵活地用于训练下游模型。不幸的是，典型的过参数化神经网络被证明对其训练数据几乎没有隐私保护。例如，对网络的梯度可以恢复出深度分类器的训练图像（Yin等人，2021），或者从大型变换器中复制训练文本序列（Carlini等人，2021）。生成模型甚至可能直接过拟合，生成的数据与其训练数据无法区分。事实上，考虑到最近的研究使用大规模从互联网抓取的数据训练功能强大的逼真图像生成器（Rombach等人，2021; Ramesh等人，2022; Saharia等人，2022; Balaji等人，2022），生成模型的过拟合和隐私泄露比以往任何时候都更加重要。为了保护训练数据的隐私，可以使用差分隐私（DP）来训练模型。差分隐私是一种严格的隐私框架，适用于统计查询（Dwork等人，2006; 2014）。在我们的情况下，这个查询对应于使用敏感数据训练神经网络。差分隐私随机梯度下降（DP-SGD）（Abadi等人，2016）是神经网络差分隐私训练的主要方法。它通过在训练过程中裁剪和添加参数梯度的噪声来保护隐私。这导致隐私和效用之间不可避免的权衡；例如，小的裁剪常数和大量的噪声注入会导致非常隐私的模型，但可能实用性不大。

例如，DP-SGD已被用于训练生成对抗网络（GANs）（Frigerio等人，2019; Torkzadehmahani等人，2019; Xie等人，2018），这些网络特别容易受到隐私泄露的影响（Webster等人，2021）。然而，虽然非私密设置中的GANs可以合成逼真的图像（Brock等人，2019; Karras等人，2020b;a; 2021），但它们在私密设置中的应用是具有挑战性的。GANs很难优化（Arjovsky＆Bottou，2017; Mescheder等人，2018），并且容易发生模式坍塌；这两种现象在DP-SGD训练期间可能会被放大。

最近，扩散模型（DMs）已经成为一类强大的生成模型（Song等人，2021c; Ho等人，2020; Sohl-Dickstein等人，2015），在图像合成方面表现出卓越的性能（Ho等人，2021; Nichol＆Dhariwal，2021; Dhariwal＆Nichol，2021; Rombach等人，2021; Ramesh等人，2022; Saharia等人，2022）。在DMs中，扩散过程逐渐扰动数据向随机噪声演变，而深度神经网络则学习去噪。DMs不仅以高质量的合成结果著称，而且具有样本多样性、简单而强大的训练目标。这使它们可能非常适合在DP扰动下进行训练。此外，在DMs中的生成对应于一个迭代去噪过程，将困难的生成任务分解为许多小的去噪步骤，每个步骤都比GANs和其他传统方法执行的一次性合成任务简单。特别是，在DMs中学习的去噪神经网络在每个合成步骤中重复应用，比一次性方法的生成器网络更简单、更平滑，这一点我们在玩具数据（合成的混合二维高斯分布）的实验证明了。因此，去噪神经网络的训练可能对于DP所需的梯度裁剪和噪声注入的敏感性可能较低。

基于这些观察，我们提出了差分隐私扩散模型（DPDMs），即在DP-SGD的严格DP保证下训练的DMs。我们深入研究了DM参数化和采样算法，并将它们量身定制到DP设置中。我们发现，在DM采样中的随机性，经验上被认为是纠错的（Karras等人，2022），在DP-SGD训练中特别有助于获得令人满意的感知质量。我们还提出了噪声多样性，其中单个训练数据样本在扩散过程中沿着多个扰动水平被重复使用进行训练（见图1）。这种简单而强大的DM训练目标的修改在不增加额外隐私成本的情况下改善了学习效果。我们在标准的DP图像生成任务上验证了DPDMs，并且在感知质量和基于我们模型生成的合成数据上训练的下游分类器的性能方面都取得了显著的优势。例如，在MNIST上，我们将最先进的FID从56.2提高到23.4，并将下游分类准确率从81.5％提高到95.3％，对于隐私设置DP-（ε=1，δ=10−5）。

我们还发现，基于DPDM生成的合成数据训练的分类器与基于真实数据训练的特定任务DP分类器的性能相当，这在DP生成模型中以前尚未证明过。我们做出了以下贡献：（i）我们仔细论证了使用DP-SGD训练DMs，并引入了DPDMs，这是首个在DP保证下训练的DMs。（ii）我们详细研究了DPDM参数化、训练设置和采样，并对其在DP设置中进行了优化。（iii）我们提出了噪声多样性以有效提升DPDM性能。（iv）在实验上，我们在广泛研究的图像建模基准测试中明显超越了DP合成的最新技术。（v）我们首次证明，基于DPDM生成的数据训练的分类器与特定任务的DP训练判别模型性能相当。这意味着DPDMs生成的合成数据的实用性非常高，实现了DP生成模型作为有效的数据共享媒介的承诺。最后，我们希望我们的工作对DMs文献产生影响，这些文献现在经常在来自不同来源的超大规模数据集上进行训练。

## 2 background

**2.1 Diffusion Models**

**2.2 Differential Privacy**

## 3 Differentially Private Diffusion Models

我们提出了DPDMs，这是使用基于DP-SGD（Abadi等人，2016）的严格DP保证训练的DMs。DP-SGD是一种已经建立的方法，用于训练DP神经网络，我们的意图不是重新发明DP-SGD；相反，这项工作的新颖之处在于将DMs与DP-SGD相结合，针对DMs的DP训练进行了修改，以及对影响DPDMs性能的设计选择和训练方法的研究。DP-SGD与GANs的结合已经被广泛研究（Frigerio等人，2019; Torkzadehmahani等人，2019; Xie等人，2018; Bie等人，2022），这促使了对DMs进行类似的研究。据我们所知，我们是首次探索DMs的DP训练。在第3.1节中，我们讨论了使用DMs进行DP生成建模的动机。然后，在第3.2节中，我们讨论了训练和方法论细节以及DM设计选择，并证明了DPDMs满足DP要求。

**3.1 Motivation**

**（i）目标函数。**到目前为止，GANs一直是DP生成建模的主力军（见第4节），尽管它们通常很难优化（Arjovsky＆Bottou，2017; Mescheder等人，2018），这是由于它们的对抗训练和易于模式崩溃的倾向。这两种现象在DP-SGD训练过程中可能会被放大。相比之下，DMs已被证明可以产生与GANs一样好甚至更好的输出（Dhariwal＆Nichol，2021），同时使用了非常简单的类回归L2损失（式（3）），这使它们在实践中具有鲁棒性和可扩展性。因此，DMs也可以说非常适合基于DP-SGD的训练，并且在梯度裁剪和添加噪声时比对抗训练框架具有更好的稳定性。

**（ii）顺序去噪。**在GANs和大多数其他传统的生成建模方法中，生成器直接学习采样函数，即将潜变量映射到合成样本的端到端映射。相比之下，DMs中的采样函数是通过顺序去噪过程定义的，将困难的生成任务分解为许多小的去噪步骤，这些步骤单独进行时比例如GAN生成器执行的一次性合成任务复杂度要低。因此，DMs中的可学习组件——去噪神经网络，在每个去噪步骤中仅被评估一次，因此比其他方法的一次性生成网络更简单、更平滑。我们将一个DM和一个GAN拟合到一个二维玩具分布（高斯混合，参见附录E），并经验性地验证了去噪器D确实比GAN学习的生成器和DM的端到端多步合成过程（概率流ODE）要简单得多（通过雅可比矩阵的Frobenius范数量化），而DM仍然能够代表出色的生成模型，这是由于其迭代合成过程。一般来说，更复杂的函数需要更大的神经网络，并且更难学习。在DP-SGD训练中，直到隐私预算耗尽，我们只有有限数量的训练迭代可用。因此，DMs对其神经网络的复杂性要求较低，这与典型的一次性生成方法相比，DMs仍然能够代表出色的生成模型，这使它们可能非常适合用于DP-SGD的DP生成建模。

**(iii) 随机扩散模型采样。**如第2.1节所讨论的，当得分模型学习不好时，使用随机采样从DMs生成样本可能比确定性采样表现更好。由于我们在DP-SGD训练中用具有偏差和大方差的估计替换了梯度估计，因此我们无法期望一个完全准确的得分模型。在第5.2节中，我们通过实验证明，随机采样实际上可以提高DPDMs的感知合成质量，如通过FID来衡量。

**3.2 Training Details, Design Choices, Privacy**

在DP-SGD中对梯度估计进行剪切和加噪（式（5））构成了高效优化的主要挑战。盲目地减少添加的噪声可能是致命的，因为这会减少在一定（ε，δ）-DP预算内允许的训练迭代次数。此外，正如讨论的那样，在DP-SGD中添加的噪声的L2范数与参数数量成线性关系。因此，对于非私密的DMs有效的设置，如相对较小的批次大小、大量的训练迭代次数和过度参数化的模型，可能对DPDMs效果不佳。下面，我们将讨论如何调整DPDMs以进行成功的DP-SGD训练。

**Noise multiplicity.** 

**定理1.** DM目标（式（7））的方差随着噪声多样性K的增加而按1/K减少。

在附录D中给出证明。直观地说，关键在于我们首先通过对多个噪声样本进行平均来创建一个相对准确且低方差的梯度估计，然后通过剪切和加噪在反向传播中进行梯度清理。这种平均化过程增加了计算成本，但在相同的隐私预算下提供了更好的效用，这是DP生成建模中的主要瓶颈；有关更多讨论，请参见附录D.3。在第5.2节中，我们通过实验证明，噪声多样性引起的方差减少是训练强DPDMs的关键因素。在图3中，我们展示了DM目标中方差的减少也从实验上导致了更低的方差梯度估计（有关实验细节，请参见附录D）。噪声多样性机制也在图1中得到了突出：图描述了单个训练样本（即，批量大小B = 1）在训练过程中的信息流。请注意，噪声多样性受到增强多样性的启发（De等人，2022），这是一种使用多个图像增强来训练带有DP-SGD的分类器的技术。与增强多样性不同，我们的新型噪声多样性专门为DPDMs设计，具有关于其方差减少的理论证明。读者可以在附录D.4中找到有关噪声多样性与数据多样性（对于DPDMs）之间区别的更详细讨论。

**神经网络规模。**目前的DMs过度参数化：例如，目前在CIFAR-10上的最先进的图像生成模型（就感知质量而言）使用了超过1亿个参数，尽管数据集仅包含5万个训练点（Karras等人，2022）。DP-SGD中每个示例的剪切操作需要计算每个训练示例的损失梯度∇θ ˜li，而不是小批量梯度。理论上，这会将内存占用量增加至少O(B)；然而，在常见的DP框架中，例如我们使用的Opacus（Yousefpour等人，2021），峰值内存需求为O(B2)，与非私有训练相比（最近的方法如幽灵剪切（Bu等人，2022）需要更少的内存，但尚未广泛实现）。除此之外，与非私有训练相比，DP-SGD通常已经依赖于显着增加的批量大小，以改善隐私与效用的权衡。因此，与其非DP对应物相比，我们为DPDMs训练了非常小的神经网络：我们在MNIST/Fashion-MNIST和CelebA上的模型分别有175万和180万个参数。此外，我们发现较小的模型在我们的实验中表现更好，这可能是由于我们的DP-SGD更新中添加的噪声的L2范数与参数数量成线性关系。这与最近在监督DP学习中的研究相反，这些研究表明较大的模型可能比较小的模型表现更好（De等人，2022; Li等人，2022b; Anil等人，2021; Li等人，2022a）。

**扩散模型配置。**除了网络大小之外，我们发现DM配置的选择，即去噪器参数化Dθ、加权函数λ(σ)和噪声分布p(σ)，也非常重要。特别是后者对于获得强DPDMs的优异结果至关重要。在图4中，我们可视化了四种考虑中的噪声分布。我们遵循Karras等人(2022)的做法，绘制了以对数噪声水平为自变量的分布p(log σ)。特别是对于高隐私设置（小ε），我们发现使用能够充分赋予较大σ权重的分布至关重要，例如v-prediction的分布（Salimans＆Ho，2022）。已知在大σ处，DM学习数据的全局、粗略结构，即数据（在我们的情况下是图像）中的低频内容。合理地学习全局结构对于形成视觉上连贯的图像并能用于训练下游模型至关重要。在非DP设置中相对容易实现这一点，因为在这些高噪声水平下，扩散分布受到了很大程度的平滑处理。然而，在高隐私级别下，即使在这种高噪声水平下进行训练也可能会面临挑战，因为DP-SGD的梯度剪切和加噪。我们假设这就是在DP设置下相对更多地给予高噪声水平更多权重的好处所在。在第5.2节中，我们通过实验证明了正确选择DM配置的重要性。

**DP-SGD设置。**我们遵循De等人（2022）的做法，使用非常大的批量大小：在MNIST/Fashion-MNIST上为4096，在CelebA上为2048。与之前的工作类似（De等人，2022; Kurakin等人，2022; Li等人，2022b），我们发现小的剪切常数C比较大的剪切规范效果更好；特别是，在我们的实验中，我们发现C = 1在不同情况下都表现良好。进一步减小C的影响很小；相反，增加C会显著降低性能。与非私有的DMs类似，我们使用可学习参数θ的指数移动平均值（EMA）。值得注意的是，最近De等人（2022）报道了这种做法对于分类器的DP-SGD训练也有积极的影响。

**隐私。**我们将隐私保护制定在Rényi差分隐私（RDP）（Mironov，2017）框架下（请参阅定义A.1），可以将其转换为（ϵ，δ）-DP。有关具有噪声多样性的DPDM训练算法，请参见算法1。为了完整起见，我们还正式证明了DPDMs的DP（释放经过清理的训练梯度˜Gbatch的DP）：

**Theorem 2.**

证明可以在附录A中找到。请注意，DP保护的强度与噪声多样性无关，如上所述。在实践中，我们通过泊松采样（见算法2）构建小批量，以通过子采样实现隐私放大（Mironov等人，2019），并通过RDP组合（Mironov，2017）计算训练DPDM的总体隐私成本。更紧密的隐私界限，例如Gopi等人（2021）开发的界限，可能会导致更好的结果，但尚未广泛实现（不在我们使用的DP-SGD库Opacus（Yousefpour等人，2021）中）。

## **4 Related Work**

在DP生成式学习文献中，一些工作（Xie等人，2018；Frigerio等人，2019；Torkzadehmahani等人，2019；Chen等人，2020）探讨了将DP-SGD（Abadi等人，2016）应用于GANs，而其他一些工作（Yoon等人，2019；Long等人，2019；Wang等人，2021）在PATE（Papernot等人，2018）框架下训练GANs，该框架将私有的教师模型（鉴别器）提炼为公共的学生（生成器）模型。除了GANs，Acs等人（2018）在DP清洗的数据簇上训练变分自动编码器，而Cao等人（2021）则使用Sinkhorn散度和DP-SGD。

DP-MERF（Harder等人，2021）是第一个对数据执行一次性私有化，然后进行非私有学习的工作。它使用差分私有随机傅里叶特征构建最大均值差异损失，然后通过生成模型将其最小化。PEARL（Liew等人，2022）相反地最小化了一个经验特征函数，也基于傅里叶特征。DP-MEPF（Harder等人，2022）将DP-MERF扩展到了混合的公共-私有设置，使用了预训练的特征提取器。虽然这些方法在高隐私/小数据集的情况下效率很高，但由于一次性私有化过程中可以提取的数据统计量的限制，它们在低隐私/大数据集的情况下的性能并不好。

在我们的实验比较中，由于对其隐私保证的担忧，我们排除了Takagi等人（2021）和Chen等人（2022）的工作。Takagi等人（2021）的隐私分析依赖于Wishart机制，由于隐私泄露已被撤回（Sarwate，2017）。Chen等人（2022）试图通过数据相关的随机响应机制来保证差分隐私，从而训练一个基于评分的模型。在附录B中，我们证明了他们提出的机制为何泄露隐私，并进一步讨论了其他隐私泄露的来源。

我们的DPDM依赖于DP-SGD（Abadi等人，2016）来实施差分隐私保证。DP-SGD还被用来训练DP分类器（Dörmann等人，2021；Tramer & Boneh，2021；Kurakin等人，2022）。最近，De等人（2022）展示了如何使用DP-SGD训练非常大的判别模型，并提出了增强多样性，这与我们在第3.2节讨论的噪声多样性相关。此外，DP-SGD已被用来训练和微调大型语言模型（Anil等人，2021；Li等人，2022b；Yu等人，2022），保护医疗领域的敏感训练数据（Ziller等人，2021a;b；Balelli等人，2022），以及模糊地理空间位置信息（Zeighami等人，2022）。

我们的工作建立在DMs和基于评分的生成模型之上（Sohl-Dickstein等人，2015；Song等人，2021c；Ho等人，2020）。DMs已经广泛用于图像合成（Ho等人，2021；Nichol＆Dhariwal，2021；Dhariwal＆Nichol，2021；Rombach等人，2021；Ramesh等人，2022；Saharia等人，2022；Balaji等人，2022）和其他图像建模任务（Meng等人，2021；Saharia等人，2021a;b；Li等人，2021；Sasaki等人，2021；Kawar等人，2022）。它们还在其他领域找到了应用，例如音频和语音生成（Chen等人，2021；Kong等人，2021；Jeong等人，2021）、视频生成（Ho等人，2022b;a；Singer等人，2023；Blattmann等人，2023）和3D合成（Luo＆Hu，2021；Zhou等人，2021；Zeng等人，2022；Kim等人，2023）。在方法上，DMs已经被改编，例如用于快速采样（Jolicoeur-Martineau等人，2021；Song等人，2021a；Salimans＆Ho，2022；Dockhorn等人，2022b；Xiao等人，2022；Watson等人，2022；Dockhorn等人，2022a）和最大似然训练（Song等人，2021b；Kingma等人，2021；Vahdat等人，2021）。据我们所知，我们是第一个在差分隐私保证下训练DMs的研究者。

## **5 Experiments**

在本节中，我们展示了DPDM在标准图像合成基准测试上的结果。重要的是，请注意，所有模型都是通过使用DP-SGD进行训练而从根本上实现隐私保护的。隐私保证由DP-SGD的（ε，δ）参数给出，下面对每个实验都清楚说明了。

**数据集。**我们专注于图像合成，并使用了MNIST（LeCun等人，2010年）、Fashion-MNIST（Xiao等人，2017年）（28x28），以及CelebA（Liu等人，2015年）（降采样至32x32）数据集。这些数据集是DP生成建模文献中的标准基准。在附录G中，我们考虑了更具挑战性的数据集并提供了初步结果。

**架构。**我们使用DDPM++架构（Song等人，2021c）实现DPDM的神经网络。详情请参阅附录C.2。

**评估。**我们通过Fréchet Inception Distance（FID）（Heusel等人，2017年）来衡量样本质量。在MNIST和Fashion-MNIST上，我们还通过在合成样本上训练分类器并计算在真实数据上的类别预测准确率来评估生成数据的类别标签的实用性。按照标准做法，我们考虑了逻辑回归（Log Reg）、MLP和CNN分类器；详情请参阅附录F.1。

**采样。**我们使用（随机的）DDIM（Song等人，2021c）和Karras等人（2022年）介绍的Churn采样器从DPDM中进行采样。详情请参阅附录C.3。

**隐私实现。**我们在PyTorch中实现了DPDM，并使用Opacus（Yousefpour等人，2021年），这是一个PyTorch中的DP-SGD库，用于训练和隐私核算。对于MNIST和Fashion-MNIST，我们使用δ=10−5；对于CelebA，我们使用δ=10−6。这些数值是标准的（Cao等人，2021年），并且选择得使得δ小于训练图像数量的倒数。与现有的DP生成建模工作类似，我们没有考虑超参数调整的（轻微）隐私成本。然而，训练和采样对超参数非常稳健，这使得DPDM成为实际隐私关键情况的理想选择；请参阅附录C.4。

**5.1 Main Results**

**类条件灰度图像生成。**对于MNIST和Fashion-MNIST，我们针对三种隐私设置进行模型训练：ε={0.2, 1, 10}（见表1）。简单来说，这三种设置分别提供高、中等和低程度的隐私保护。DPDMs在ε=0.2时使用v-prediction DM配置（Salimans & Ho，2022），在ε={1, 10}时使用EDM配置（Karras等人，2022）；请参见第5.2节。我们使用了Churn采样器（Karras等人，2022）：(FID)和(Acc)这两个设置基于相同的DM，仅在采样器设置上有所不同；请参见表14和表15以获取所有采样器设置。

DPDMs在所有的隐私设置和所有的度量标准上都以较大的优势胜过所有其他现有模型（见表1）。有趣的是，DPDM还在24个设置中的22个中胜过了DP-MEPF（Harder等人，2022），后者是在额外的公共数据上进行训练的方法。ε=10的生成样本如图5所示。从视觉上看，DPDM的样本质量明显优于基线模型的。

**与使用DP-SGD训练的分类器相比较。**直接使用DP-SGD训练特定任务的私有分类器，还是使用DPDM生成的合成数据训练非私有分类器在下游任务上表现更好？为了回答这个问题，我们使用DP-SGD在真实（训练）数据上训练私有分类器，并将它们与我们使用DPDM合成数据学习的分类器进行比较（详细信息见附录F.3）。为了进行公平比较，我们使用了与主要实验中已经使用过的相同架构来量化下游分类准确性（结果见表2；我们在真实（测试）数据上进行测试）。虽然直接在真实数据上使用DP-SGD训练的逻辑回归模型在所有六个设置中都优于DPDM下游分类器（符合经验发现，使用DP-SGD训练参数较少的分类器比训练参数较多的分类器更容易（Tramer＆Boneh，2021）），但在DPDM的合成数据上训练的CNN分类器通常优于DP-SGD训练的分类器。这些结果表明，DPDM生成的合成数据具有非常高的效用，表明DPDMs在实践中可能被用作一种有效的、保护隐私的数据共享介质。事实上，这种方法比使用DP-SGD训练特定任务的模型更有益，因为用户可以从DPDMs中生成他们想要的任意数量的数据，用于各种下游应用，而无需进一步考虑隐私问题。据我们所知，在DP生成建模文献中以前从未证明过，由DP生成模型生成的图像数据可以用于训练与直接使用DP-SGD训练的特定任务模型相媲美的判别模型。

**无条件彩色图像生成。**在CelebA数据集上，我们针对ε={1, 10}训练模型（见表4）。两个DPDMs都使用EDM配置（Karras等人，2022年）以及Churn采样器；请参阅表14。对于ε=10，DPDM再次以显着的优势胜过现有方法。DPDM生成的图像（见图16）比基线的样本更加多样且生动。

**5.2 Ablation Studies**

**噪声多样性。**表5显示了使用不同噪声多样性K（使用v-prediction DM配置）（Salimans＆Ho，2022年）训练的DPDMs的结果。如预期的那样，增加K会导致性能总体上的提升趋势；然而，这些指标在K=32左右开始趋于稳定。

**扩散模型配置。**我们使用不同的DM配置训练DPDMs（见App. C.1）。基于VP和VE的模型（Song等人，2021c）在所有设置下表现不佳，而对于ε=0.2，v-prediction在MNIST上明显优于EDM配置（表3）。在Fashion-MNIST上，这种优势不太明显（扩展表12）。对于ε={1, 10}，EDM配置的表现优于v-prediction。请注意，这些配置的去噪参数化几乎相同，它们的主要区别在于噪声分布p(σ)（图4）。正如在第3.2节中讨论的那样，对于大的隐私设置（小的ε），超采样大噪声水平σ预计尤其重要，我们的消融验证了这一点。

**抽样。**表6显示了不同抽样器的结果：确定性和随机DDIM（Song等人，2021a），以及Churn抽样器（针对高FID分数和下游准确性进行调优）；有关抽样器的详细信息，请参见App. C.3。随机抽样对于获得良好的感知质量（由FID测量）至关重要（请参见确定性DDIM的性能较差），而对于下游准确性而言则不那么重要。我们假设FID更好地捕捉了需要足够准确的合成过程的图像细节。如第2.1节和3.1节所讨论的，随机抽样可以帮助实现这一点，因此在DP-SGD训练的DMs中特别重要。我们还观察到，随着ε的增加，与随机DDIM相比，Churn抽样器的优势变得不那么显著。此外，特别是对于ε=0.2，经过FID调整的Churn抽样器在下游准确性上表现不佳。这可能是因为其设置牺牲了样本多样性，而下游准确性通常受益于样本质量（还请参见App. F.5中的样本）。

## **6 Conclusions**

我们提出了差分隐私扩散模型（DPDMs），它利用DP-SGD来强制实现差分隐私的保证。由于其强大的训练目标和固有的较简单的去噪神经网络，DMs是差分隐私生成学习的强有力候选者。为了在训练过程中减少梯度方差，我们引入了噪声多样性，并发现DPDMs在常见的DP图像生成基准测试中取得了最先进的性能。此外，使用DPDM生成的合成数据训练的下游分类器的性能与直接使用DP-SGD训练的特定任务的判别模型相媲美。值得注意的是，尽管DPDMs取得了最先进的结果，但它们是基于一个简单直观的思想，即将DMs与DP-SGD进行精心结合（利用新颖的噪声多样性）。这种“简单性”是一个关键优势，因为它使得DPDMs成为一个潜在的强大工具，可以轻松被差分隐私从业者采用。基于我们有希望的结果，我们得出结论认为DMs是差分隐私生成学习的理想框架。此外，考虑到基于DM的大规模逼真图像生成系统（Rombach等人，2021；Saharia等人，2022；Ramesh等人，2022；Balaji等人，2022）的极快进展，我们认为推进基于DM的差分隐私生成建模是一个紧迫的课题。作为未来的方向，我们设想在这些大规模图像生成DM的训练过程中应用我们的DPDM方法，以及将DPDMs应用于其他类型的数据。此外，对我们的DPDMs进行预训练，使用不受隐私约束的公共数据，类似于Harder等人（2022），可能会提高性能。另请参阅附录H，进一步讨论伦理、可重现性、限制和更多未来工作。



# 项目研究概述

现代机器学习模型依赖于越来越大的训练数据集，然而在涉及隐私敏感领域时，数据集的使用往往受到限制。利用差分隐私（DP）在敏感数据上训练来生成模型可以规避这一挑战，提供对合成数据的访问。我们建立在最近扩散模型（DMs）取得的成功基础上，引入差分隐私扩散模型（DPDMs），利用差分隐私随机梯度下降算法（DP-SGD）来实现隐私保护。

我们提出了差分隐私扩散模型（DPDMs），它利用DP-SGD来强制实现差分隐私的保证。由于其强大的训练目标和固有的较简单的去噪神经网络，DMs是差分隐私生成学习的强有力候选者。我们研究了扩散模型参数化和采样算法，在DPDMs中它们被证明是关键因素；为了在训练过程中减少梯度方差，我们使用了噪声多样性作为一个标准，并发现DPDMs在常见的DP图像生成基准测试中有良好的性能。

此外，使用DPDM生成的合成数据训练的下游分类器的性能与直接使用DP-SGD训练的特定任务的判别模型相媲美。值得注意的是，尽管DPDMs取得了一定的结果，但它们是基于一个简单直观的思想，即将DMs与DP-SGD进行精心结合，而这种简单的结合，可以轻松被专注于差分隐私的模型使用者采用。

基于我们实验的结果，我们得出结论认为DMs是差分隐私生成学习的理想框架。此外，考虑到基于DM的大规模逼真图像生成系统的极快进展，我们认为基于DM的差分隐私生成建模是一个未来的方向，我们设想在这些大规模图像生成DM的训练过程中应用DPDM方法，以及将DPDMs应用于其他类型的数据。此外，对我们的DPDMs进行预训练，使用不受隐私约束的公共数据，可能会提高性能。



# 答辩

**应用**

这一模型学习控制蛋白质形成方式的生化关系，预测各种新氨基酸序列，产生超越自然界的新蛋白质，从而实现独特应用，例如，该工具开发的食品涂层可使农产品保鲜时间更长，同时保证食用安全。该模型还可在几天内就生成数百万种蛋白质，为科学家迅速提供可供探索的新可能。

**GAN 的主要思想：**

GAN 就是一个互搏的过程，要训练两个网络，一个是生成器，一个是判别器
生成器就是给定一个随机噪声，生成一些东西，我们希望其能生成一个比较逼真的图片，把生成的图片和真实的图片给到判别器，让判别器来看哪些是真图片和假图片，就是 0/1 的判断
通过两个网络互相学习，互相提高，最后能生成比较真实的图片
缺点：

可解释性较差：GAN 不是概率模型，是通过网络完成的，是隐式的，所以不知道它到底学到了什么，不知道其遵循了什么分布
训练时不稳定：因为要同时训练两个网络，就有需要平衡的问题，训练不好的话容易模型坍塌
多样性较差
优点：

GAN 的目标函数是用来以假乱真的，所以保真度和细节都非常好



**公式**：

SGD：

$\theta \to \theta - \frac{\eta}{B}(\sum l_i(\theta))$

DP-SGD：

$\theta \to \theta - \frac{\eta}{B}(\sum clip_c(l_i(\theta)) + Cz))$

损失函数:

$l_k = \lambda(\sigma_k) ||D_\theta(X_k,\sigma_k) - x||_2^2)$

模型函数：

$D_\theta(X_k,\sigma_k)$

噪声平均：

$l = \frac{1}{K} \sum{l_k}$
